// what is tokinaizing ??

/*
----------> **** <---------
|||||||||||||||||||||||||||
A lexical analyzer, also known as a lexer or tokenizer, is a component of a parser that performs the first step of the parsing process: lexical analysis. Its primary task is to break down the input code or text into a sequence of tokens.

The lexical analyzer scans the input character by character and groups them into meaningful units called tokens. Each token represents a specific element of the programming language, such as keywords, identifiers, operators, literals, or punctuation symbols.
|||||||||||||||||||||||||||
----------> **** <---------
*/

// examples to clear understanding
// lets declare the varaible y
const y = 1;
// so here the tokinaizer will be like this:=>:   const , y , = , 1, ;

/*
 // lets understand what happen here 

 1- const : we declare the varaible 
 2- javascript excpect that you what come after the declaring the varaible will assign the name 
---------------->
 test case => { if we put let and after it let we will get error because we use a declaring varaible as name javascript in this example does not it like we tell it to declare varaible and when its waiting for the name we give it anothe declaration which cause the error }
---------------->
3- the assignement symbole = 
4- 1 number :)

*/
